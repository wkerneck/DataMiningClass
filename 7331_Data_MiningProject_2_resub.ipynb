{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# ![.right](https://lh6.ggpht.com/wUrTIhpHPVqw_VPCdhbSiF5TXlBlLyRHdH1gsII_y5NkgYKzbbj7cC2l6AGoVq-JN0U=w100 \"MSDS 7331 Data Mining - Project 1\")\n",
    "\n",
    "\n",
    "# Project 2: Classification\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "# Team Members\n",
    "\n",
    "- Chris Woodard\n",
    "- Claire Chu\n",
    "- Nathan Mowat\n",
    "- Bill Kerneckel\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Rubic\n",
    "\n",
    "- [Data Preperation 1](#dp1) \n",
    "\n",
    "- [Data Preperation 2](#dp2)\n",
    "\n",
    "- [Modeling and Evaluation 1](#me1)\n",
    "\n",
    "- [Modeling and Evaluation 2](#me2)\n",
    "\n",
    "- [Modeling and Evaluation 3](#me3)\n",
    "\n",
    "- [Modeling and Evaluation 4](#me4)\n",
    "\n",
    "- [Modeling and Evaluation 5](#me5)\n",
    "\n",
    "- [Modeling and Evaluation 6](#me6)\n",
    "\n",
    "- [Deployment](#d)\n",
    "\n",
    "- [Exceptional Work](#ew)\n",
    "\n",
    "- [Appendix](#a)\n",
    "\n",
    "<hr>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# OBJECTIVE: \n",
    "Using the NASA human resources dataset, let's use the variables to predict future records:\n",
    "- What kind of model can we use to predict a \"junior salary range level\" classification, given the variables we have?\n",
    "- What kind of model can we use to predict a \"caucasian\" race classification, given the variables we have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Data Preperation 1\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<span style=\"color:red\">10 Points - Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#load python libaries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as pl\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "import ggplot\n",
    "import datetime\n",
    "import time\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#load data file\n",
    "data_file = pd.read_excel('/Users/macnificent/desktop/NEW_NASA_2006.xlsx') \n",
    "data_file2 = pd.read_excel('/Users/macnificent/desktop/NEW_NASA_2007.xlsx') \n",
    "data_file3 = pd.read_excel('/Users/macnificent/desktop/NASA_2008.xlsx')\n",
    "data_file4 = pd.read_excel('/Users/macnificent/desktop/NASA_2009.xlsx')\n",
    "data_file5 = pd.read_excel('/Users/macnificent/desktop/NASA_2010.xlsx')\n",
    "data_file6 = pd.read_excel('/Users/macnificent/desktop/NASA_2011.xlsx')\n",
    "data_file7 = pd.read_excel('/Users/macnificent/desktop/NASA_2012.xlsx')\n",
    "data_file8 = pd.read_excel('/Users/macnificent/desktop/NASA_2013.xlsx')\n",
    "data_file9 = pd.read_excel('/Users/macnificent/desktop/NASA_2014.xlsx')\n",
    "data_file10 = pd.read_excel('/Users/macnificent/desktop/NASA_2015.xlsx')\n",
    "data_file11 = pd.read_excel('/Users/macnificent/desktop/NASA_2016.xlsx')\n",
    "\n",
    "#you'll have to change the file path to your working directory\n",
    "\n",
    "#removing 1st row from datasets\n",
    "data_file.drop(0, axis = 0,inplace = True)\n",
    "data_file2.drop(0, axis = 0,inplace = True)\n",
    "data_file3.drop(0, axis = 0,inplace = True)\n",
    "data_file4.drop(0, axis = 0,inplace = True)\n",
    "data_file5.drop(0, axis = 0,inplace = True)\n",
    "data_file6.drop(0, axis = 0,inplace = True)\n",
    "data_file7.drop(0, axis = 0,inplace = True)\n",
    "data_file8.drop(0, axis = 0,inplace = True)\n",
    "data_file9.drop(0, axis = 0,inplace = True)\n",
    "data_file10.drop(0, axis = 0,inplace = True)\n",
    "data_file11.drop(0, axis = 0,inplace = True)\n",
    "\n",
    "#note: please be patient as this will take a few minutes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Hist_yr</th>\n",
       "      <th>Unnamed: 28</th>\n",
       "      <th>agency</th>\n",
       "      <th>bdyr</th>\n",
       "      <th>coopsch</th>\n",
       "      <th>coopyr</th>\n",
       "      <th>currgrddte</th>\n",
       "      <th>dtystn_ind</th>\n",
       "      <th>dtystnname</th>\n",
       "      <th>...</th>\n",
       "      <th>sex</th>\n",
       "      <th>step_emp</th>\n",
       "      <th>supind</th>\n",
       "      <th>suplev</th>\n",
       "      <th>tenure</th>\n",
       "      <th>time_in_grade</th>\n",
       "      <th>tl</th>\n",
       "      <th>ttl</th>\n",
       "      <th>typappt</th>\n",
       "      <th>worksch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN51</td>\n",
       "      <td>1900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/08/1989</td>\n",
       "      <td>80</td>\n",
       "      <td>GREENBELT,PRINCE GEORGE'S,MARYLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>205.46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN51</td>\n",
       "      <td>1980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09/22/2002</td>\n",
       "      <td>80</td>\n",
       "      <td>GREENBELT,PRINCE GEORGE'S,MARYLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>50.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN23</td>\n",
       "      <td>1986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07/21/1996</td>\n",
       "      <td>88</td>\n",
       "      <td>HAMPTON,HAMPTON,VIRGINIA</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>124.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN64</td>\n",
       "      <td>1994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04/17/2005</td>\n",
       "      <td>88</td>\n",
       "      <td>STENNIS SPACE CENTER, HANCOCK, MISSISSIPPI</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>19.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN72</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07/23/2006</td>\n",
       "      <td>29</td>\n",
       "      <td>HOUSTON,HARRIS,TEXAS</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>3.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN62</td>\n",
       "      <td>1972</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/01/1997</td>\n",
       "      <td>32</td>\n",
       "      <td>REDSTONE ARSENAL,MADISON,ALABAMA</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>107.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN51</td>\n",
       "      <td>1900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02/27/2000</td>\n",
       "      <td>80</td>\n",
       "      <td>GREENBELT,PRINCE GEORGE'S,MARYLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>80.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN72</td>\n",
       "      <td>1986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04/26/1998</td>\n",
       "      <td>29</td>\n",
       "      <td>HOUSTON,HARRIS,TEXAS</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>102.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN51</td>\n",
       "      <td>1978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09/27/1987</td>\n",
       "      <td>80</td>\n",
       "      <td>GREENBELT,PRINCE GEORGE'S,MARYLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>229.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN10</td>\n",
       "      <td>1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>05/14/2006</td>\n",
       "      <td>80</td>\n",
       "      <td>WASHINGTON,DISTRICT OF COLUMBIA</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>6.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN62</td>\n",
       "      <td>1982</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07/30/2000</td>\n",
       "      <td>32</td>\n",
       "      <td>REDSTONE ARSENAL,MADISON,ALABAMA</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>75.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN72</td>\n",
       "      <td>1976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09/29/1989</td>\n",
       "      <td>29</td>\n",
       "      <td>HOUSTON,HARRIS,TEXAS</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>205.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN22</td>\n",
       "      <td>1973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04/04/2004</td>\n",
       "      <td>14</td>\n",
       "      <td>BROOK PARK,CUYAHOGA,OHIO</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>31.59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN10</td>\n",
       "      <td>1975</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>03/30/1997</td>\n",
       "      <td>80</td>\n",
       "      <td>WASHINGTON,DISTRICT OF COLUMBIA</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>115.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN76</td>\n",
       "      <td>1978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/23/1984</td>\n",
       "      <td>88</td>\n",
       "      <td>KENNEDY SPACE CENTER,BREVARD,FLORIDA</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>262.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN21</td>\n",
       "      <td>1980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07/14/2002</td>\n",
       "      <td>74</td>\n",
       "      <td>MOFFETT FIELD,SANTA CLARA,CALIFORNIA</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>52.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN21</td>\n",
       "      <td>1979</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>03/21/2004</td>\n",
       "      <td>74</td>\n",
       "      <td>MOFFETT FIELD,SANTA CLARA,CALIFORNIA</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>32.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN51</td>\n",
       "      <td>2003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/27/2005</td>\n",
       "      <td>80</td>\n",
       "      <td>GREENBELT,PRINCE GEORGE'S,MARYLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>11.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN10</td>\n",
       "      <td>1978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>03/21/1993</td>\n",
       "      <td>41</td>\n",
       "      <td>PASADENA,LOS ANGELES,CALIFORNIA</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>164.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN22</td>\n",
       "      <td>1983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/18/1990</td>\n",
       "      <td>14</td>\n",
       "      <td>BROOK PARK,CUYAHOGA,OHIO</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>192.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN62</td>\n",
       "      <td>1999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07/15/2001</td>\n",
       "      <td>32</td>\n",
       "      <td>REDSTONE ARSENAL,MADISON,ALABAMA</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>64.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN76</td>\n",
       "      <td>1900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/13/2005</td>\n",
       "      <td>88</td>\n",
       "      <td>KENNEDY SPACE CENTER,BREVARD,FLORIDA</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>12.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN51</td>\n",
       "      <td>1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/25/2002</td>\n",
       "      <td>80</td>\n",
       "      <td>GREENBELT,PRINCE GEORGE'S,MARYLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>50.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN76</td>\n",
       "      <td>1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/15/2006</td>\n",
       "      <td>88</td>\n",
       "      <td>KENNEDY SPACE CENTER,BREVARD,FLORIDA</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>1.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN51</td>\n",
       "      <td>2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04/16/2006</td>\n",
       "      <td>80</td>\n",
       "      <td>GREENBELT,PRINCE GEORGE'S,MARYLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>7.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN72</td>\n",
       "      <td>1967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01/08/1989</td>\n",
       "      <td>29</td>\n",
       "      <td>HOUSTON,HARRIS,TEXAS</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>214.46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN10</td>\n",
       "      <td>1972</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01/09/2006</td>\n",
       "      <td>80</td>\n",
       "      <td>WASHINGTON,DISTRICT OF COLUMBIA</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>10.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN76</td>\n",
       "      <td>1982</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/12/2006</td>\n",
       "      <td>88</td>\n",
       "      <td>KENNEDY SPACE CENTER,BREVARD,FLORIDA</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>0.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN51</td>\n",
       "      <td>1900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/30/2005</td>\n",
       "      <td>80</td>\n",
       "      <td>GREENBELT,PRINCE GEORGE'S,MARYLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>12.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN72</td>\n",
       "      <td>1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06/12/2005</td>\n",
       "      <td>29</td>\n",
       "      <td>HOUSTON,HARRIS,TEXAS</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>17.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202707</th>\n",
       "      <td>17498</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN51</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>08/05/2007</td>\n",
       "      <td>80</td>\n",
       "      <td>GREENBELT,PRINCE GEORGE'S,MARYLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>109.59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AEROSPACE FLIGHT SYSTEMS</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202708</th>\n",
       "      <td>17499</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN51</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>05/04/2014</td>\n",
       "      <td>80</td>\n",
       "      <td>GREENBELT,PRINCE GEORGE'S,MARYLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>28.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RVISORY AST, SOFTWARE SYSTEMS</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202709</th>\n",
       "      <td>17500</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN23</td>\n",
       "      <td>1991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>02/26/2012</td>\n",
       "      <td>88</td>\n",
       "      <td>HAMPTON,HAMPTON,VIRGINIA</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>54.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202710</th>\n",
       "      <td>17501</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN10</td>\n",
       "      <td>2005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>08/07/2016</td>\n",
       "      <td>88</td>\n",
       "      <td>BAY ST LOUIS,HANCOCK,MISSISSIPPI</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202711</th>\n",
       "      <td>17502</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN23</td>\n",
       "      <td>1900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10/02/2005</td>\n",
       "      <td>88</td>\n",
       "      <td>HAMPTON,HAMPTON,VIRGINIA</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>131.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202712</th>\n",
       "      <td>17503</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN23</td>\n",
       "      <td>2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>07/12/2015</td>\n",
       "      <td>88</td>\n",
       "      <td>HAMPTON,HAMPTON,VIRGINIA</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>14.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ARCH AST, AEROSPACE MATERIALS</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202713</th>\n",
       "      <td>17504</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN72</td>\n",
       "      <td>1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>07/24/1994</td>\n",
       "      <td>29</td>\n",
       "      <td>HOUSTON,HARRIS,TEXAS</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>265.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>, TELECOMMUNICATIONS)</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202714</th>\n",
       "      <td>17505</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN51</td>\n",
       "      <td>1997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>03/11/2012</td>\n",
       "      <td>80</td>\n",
       "      <td>GREENBELT,PRINCE GEORGE'S,MARYLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>54.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202715</th>\n",
       "      <td>17506</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN51</td>\n",
       "      <td>1900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10/19/2014</td>\n",
       "      <td>80</td>\n",
       "      <td>GREENBELT,PRINCE GEORGE'S,MARYLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>23.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202716</th>\n",
       "      <td>17507</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN51</td>\n",
       "      <td>1900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>07/24/2016</td>\n",
       "      <td>80</td>\n",
       "      <td>GREENBELT,PRINCE GEORGE'S,MARYLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202717</th>\n",
       "      <td>17508</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN76</td>\n",
       "      <td>1997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>06/27/2004</td>\n",
       "      <td>54</td>\n",
       "      <td>KENNEDY SPACE CENTER,BREVARD,FLORIDA</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>146.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202718</th>\n",
       "      <td>17509</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN24</td>\n",
       "      <td>1997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>06/12/2016</td>\n",
       "      <td>41</td>\n",
       "      <td>EDWARDS AFB,KERN,CALIFORNIA</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>3.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202719</th>\n",
       "      <td>17510</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN51</td>\n",
       "      <td>1983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>05/05/2002</td>\n",
       "      <td>80</td>\n",
       "      <td>GREENBELT,PRINCE GEORGE'S,MARYLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>172.59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202720</th>\n",
       "      <td>17511</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN51</td>\n",
       "      <td>1991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>03/28/2010</td>\n",
       "      <td>80</td>\n",
       "      <td>GREENBELT,PRINCE GEORGE'S,MARYLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>77.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>, AEROSPACE FLIGHT SYSTEMS)</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202721</th>\n",
       "      <td>17512</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN10</td>\n",
       "      <td>1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10/11/2009</td>\n",
       "      <td>80</td>\n",
       "      <td>WASHINGTON,DISTRICT OF COLUMBIA</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>83.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202722</th>\n",
       "      <td>17513</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN21</td>\n",
       "      <td>1900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>03/13/2011</td>\n",
       "      <td>03</td>\n",
       "      <td>ALBUQUERQUE,BERNALILLO,NEW MEXICO</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>66.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202723</th>\n",
       "      <td>17514</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN72</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>09/08/1991</td>\n",
       "      <td>29</td>\n",
       "      <td>HOUSTON,HARRIS,TEXAS</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>300.49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>, AEROSPACE FLIGHT SYSTEMS)</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202724</th>\n",
       "      <td>17515</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN51</td>\n",
       "      <td>1989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>02/09/2014</td>\n",
       "      <td>80</td>\n",
       "      <td>GREENBELT,PRINCE GEORGE'S,MARYLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>31.46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202725</th>\n",
       "      <td>17516</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN62</td>\n",
       "      <td>2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11/05/2012</td>\n",
       "      <td>32</td>\n",
       "      <td>REDSTONE ARSENAL,MADISON,ALABAMA</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>46.59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ARCH AST, FIELDS AND PARTICLES</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202726</th>\n",
       "      <td>17517</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN51</td>\n",
       "      <td>1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>07/02/2000</td>\n",
       "      <td>80</td>\n",
       "      <td>GREENBELT,PRINCE GEORGE'S,MARYLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>194.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AEROSPACE FLIGHT SYSTEMS</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202727</th>\n",
       "      <td>17518</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN51</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10/26/2009</td>\n",
       "      <td>80</td>\n",
       "      <td>GREENBELT,PRINCE GEORGE'S,MARYLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>82.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>,ATMOSPHERIC CHEMISTRY &amp; DYNAMIC)</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202728</th>\n",
       "      <td>17519</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN72</td>\n",
       "      <td>1990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>04/03/2016</td>\n",
       "      <td>29</td>\n",
       "      <td>HOUSTON,HARRIS,TEXAS</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>5.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202729</th>\n",
       "      <td>17520</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN21</td>\n",
       "      <td>1985</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>09/30/2007</td>\n",
       "      <td>74</td>\n",
       "      <td>MOFFETT FIELD,SANTA CLARA,CALIFORNIA</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>107.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FLUID MECHANICS</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202730</th>\n",
       "      <td>17521</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN62</td>\n",
       "      <td>2009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>09/19/2016</td>\n",
       "      <td>32</td>\n",
       "      <td>REDSTONE ARSENAL,MADISON,ALABAMA</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>0.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ARCH AST, FIELDS AND PARTICLES</td>\n",
       "      <td>15</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202731</th>\n",
       "      <td>17522</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN51</td>\n",
       "      <td>1974</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>01/30/2000</td>\n",
       "      <td>80</td>\n",
       "      <td>GREENBELT,PRINCE GEORGE'S,MARYLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>199.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AEROSPACE FLIGHT SYSTEMS</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202732</th>\n",
       "      <td>17523</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN21</td>\n",
       "      <td>1980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10/29/2006</td>\n",
       "      <td>74</td>\n",
       "      <td>MOFFETT FIELD,SANTA CLARA,CALIFORNIA</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>118.81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202733</th>\n",
       "      <td>17524</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN76</td>\n",
       "      <td>1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>01/11/2004</td>\n",
       "      <td>54</td>\n",
       "      <td>KENNEDY SPACE CENTER,BREVARD,FLORIDA</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>152.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>, SAFETY &amp; MISSION ASSURANCE)</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202734</th>\n",
       "      <td>17525</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN51</td>\n",
       "      <td>1984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>08/26/2001</td>\n",
       "      <td>80</td>\n",
       "      <td>GREENBELT,PRINCE GEORGE'S,MARYLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>180.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202735</th>\n",
       "      <td>17526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202736</th>\n",
       "      <td>17527</td>\n",
       "      <td>(17525 row(s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>) affec</td>\n",
       "      <td>ted)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202737 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index       Hist_yr Unnamed: 28   agency  bdyr coopsch coopyr  \\\n",
       "0           1          2006         NaN     NN51  1900     NaN    NaN   \n",
       "1           2          2006         NaN     NN51  1980     NaN    NaN   \n",
       "2           3          2006         NaN     NN23  1986     NaN    NaN   \n",
       "3           4          2006         NaN     NN64  1994     NaN    NaN   \n",
       "4           5          2006         NaN     NN72  2006     NaN    NaN   \n",
       "5           6          2006         NaN     NN62  1972     NaN    NaN   \n",
       "6           7          2006         NaN     NN51  1900     NaN    NaN   \n",
       "7           8          2006         NaN     NN72  1986     NaN    NaN   \n",
       "8           9          2006         NaN     NN51  1978     NaN    NaN   \n",
       "9          10          2006         NaN     NN10  1987     NaN    NaN   \n",
       "10         11          2006         NaN     NN62  1982     NaN    NaN   \n",
       "11         12          2006         NaN     NN72  1976     NaN    NaN   \n",
       "12         13          2006         NaN     NN22  1973     NaN    NaN   \n",
       "13         14          2006         NaN     NN10  1975     NaN    NaN   \n",
       "14         15          2006         NaN     NN76  1978     NaN    NaN   \n",
       "15         16          2006         NaN     NN21  1980     NaN    NaN   \n",
       "16         17          2006         NaN     NN21  1979     NaN    NaN   \n",
       "17         18          2006         NaN     NN51  2003     NaN    NaN   \n",
       "18         19          2006         NaN     NN10  1978     NaN    NaN   \n",
       "19         20          2006         NaN     NN22  1983     NaN    NaN   \n",
       "20         21          2006         NaN     NN62  1999     NaN    NaN   \n",
       "21         22          2006         NaN     NN76  1900     NaN    NaN   \n",
       "22         23          2006         NaN     NN51  1987     NaN    NaN   \n",
       "23         24          2006         NaN     NN76  1995     NaN    NaN   \n",
       "24         25          2006         NaN     NN51  2002     NaN    NaN   \n",
       "25         26          2006         NaN     NN72  1967     NaN    NaN   \n",
       "26         27          2006         NaN     NN10  1972     NaN    NaN   \n",
       "27         28          2006         NaN     NN76  1982     NaN    NaN   \n",
       "28         29          2006         NaN     NN51  1900     NaN    NaN   \n",
       "29         30          2006         NaN     NN72  1996     NaN    NaN   \n",
       "...       ...           ...         ...      ...   ...     ...    ...   \n",
       "202707  17498          2016         NaN     NN51  1992     NaN      0   \n",
       "202708  17499          2016         NaN     NN51  1992     NaN      0   \n",
       "202709  17500          2016         NaN     NN23  1991     NaN      0   \n",
       "202710  17501          2016         NaN     NN10  2005     NaN      0   \n",
       "202711  17502          2016         NaN     NN23  1900     NaN      0   \n",
       "202712  17503          2016         NaN     NN23  2008     NaN      0   \n",
       "202713  17504          2016         NaN     NN72  1987     NaN      0   \n",
       "202714  17505          2016         NaN     NN51  1997     NaN      0   \n",
       "202715  17506          2016         NaN     NN51  1900     NaN      0   \n",
       "202716  17507          2016         NaN     NN51  1900     NaN      0   \n",
       "202717  17508          2016         NaN     NN76  1997     NaN      0   \n",
       "202718  17509          2016         NaN     NN24  1997     NaN      0   \n",
       "202719  17510          2016         NaN     NN51  1983     NaN      0   \n",
       "202720  17511          2016         NaN     NN51  1991     NaN      0   \n",
       "202721  17512          2016         NaN     NN10  1987     NaN      0   \n",
       "202722  17513          2016         NaN     NN21  1900     NaN      0   \n",
       "202723  17514          2016         NaN     NN72  2013     NaN      0   \n",
       "202724  17515          2016         NaN     NN51  1989     NaN      0   \n",
       "202725  17516          2016         NaN     NN62  2010     NaN      0   \n",
       "202726  17517          2016         NaN     NN51  1987     NaN      0   \n",
       "202727  17518          2016         NaN     NN51  2006     NaN      0   \n",
       "202728  17519          2016         NaN     NN72  1990     NaN      0   \n",
       "202729  17520          2016         NaN     NN21  1985     NaN      0   \n",
       "202730  17521          2016         NaN     NN62  2009     NaN      0   \n",
       "202731  17522          2016         NaN     NN51  1974     NaN      0   \n",
       "202732  17523          2016         NaN     NN21  1980     NaN      0   \n",
       "202733  17524          2016         NaN     NN76  1987     NaN      0   \n",
       "202734  17525          2016         NaN     NN51  1984     NaN      0   \n",
       "202735  17526           NaN         NaN      NaN   NaN     NaN    NaN   \n",
       "202736  17527  (17525 row(s         NaN  ) affec  ted)     NaN    NaN   \n",
       "\n",
       "        currgrddte dtystn_ind                                  dtystnname  \\\n",
       "0       10/08/1989         80          GREENBELT,PRINCE GEORGE'S,MARYLAND   \n",
       "1       09/22/2002         80          GREENBELT,PRINCE GEORGE'S,MARYLAND   \n",
       "2       07/21/1996         88                    HAMPTON,HAMPTON,VIRGINIA   \n",
       "3       04/17/2005         88  STENNIS SPACE CENTER, HANCOCK, MISSISSIPPI   \n",
       "4       07/23/2006         29                        HOUSTON,HARRIS,TEXAS   \n",
       "5       12/01/1997         32            REDSTONE ARSENAL,MADISON,ALABAMA   \n",
       "6       02/27/2000         80          GREENBELT,PRINCE GEORGE'S,MARYLAND   \n",
       "7       04/26/1998         29                        HOUSTON,HARRIS,TEXAS   \n",
       "8       09/27/1987         80          GREENBELT,PRINCE GEORGE'S,MARYLAND   \n",
       "9       05/14/2006         80             WASHINGTON,DISTRICT OF COLUMBIA   \n",
       "10      07/30/2000         32            REDSTONE ARSENAL,MADISON,ALABAMA   \n",
       "11      09/29/1989         29                        HOUSTON,HARRIS,TEXAS   \n",
       "12      04/04/2004         14                    BROOK PARK,CUYAHOGA,OHIO   \n",
       "13      03/30/1997         80             WASHINGTON,DISTRICT OF COLUMBIA   \n",
       "14      12/23/1984         88        KENNEDY SPACE CENTER,BREVARD,FLORIDA   \n",
       "15      07/14/2002         74        MOFFETT FIELD,SANTA CLARA,CALIFORNIA   \n",
       "16      03/21/2004         74        MOFFETT FIELD,SANTA CLARA,CALIFORNIA   \n",
       "17      11/27/2005         80          GREENBELT,PRINCE GEORGE'S,MARYLAND   \n",
       "18      03/21/1993         41             PASADENA,LOS ANGELES,CALIFORNIA   \n",
       "19      11/18/1990         14                    BROOK PARK,CUYAHOGA,OHIO   \n",
       "20      07/15/2001         32            REDSTONE ARSENAL,MADISON,ALABAMA   \n",
       "21      11/13/2005         88        KENNEDY SPACE CENTER,BREVARD,FLORIDA   \n",
       "22      08/25/2002         80          GREENBELT,PRINCE GEORGE'S,MARYLAND   \n",
       "23      10/15/2006         88        KENNEDY SPACE CENTER,BREVARD,FLORIDA   \n",
       "24      04/16/2006         80          GREENBELT,PRINCE GEORGE'S,MARYLAND   \n",
       "25      01/08/1989         29                        HOUSTON,HARRIS,TEXAS   \n",
       "26      01/09/2006         80             WASHINGTON,DISTRICT OF COLUMBIA   \n",
       "27      11/12/2006         88        KENNEDY SPACE CENTER,BREVARD,FLORIDA   \n",
       "28      10/30/2005         80          GREENBELT,PRINCE GEORGE'S,MARYLAND   \n",
       "29      06/12/2005         29                        HOUSTON,HARRIS,TEXAS   \n",
       "...            ...        ...                                         ...   \n",
       "202707  08/05/2007         80          GREENBELT,PRINCE GEORGE'S,MARYLAND   \n",
       "202708  05/04/2014         80          GREENBELT,PRINCE GEORGE'S,MARYLAND   \n",
       "202709  02/26/2012         88                    HAMPTON,HAMPTON,VIRGINIA   \n",
       "202710  08/07/2016         88            BAY ST LOUIS,HANCOCK,MISSISSIPPI   \n",
       "202711  10/02/2005         88                    HAMPTON,HAMPTON,VIRGINIA   \n",
       "202712  07/12/2015         88                    HAMPTON,HAMPTON,VIRGINIA   \n",
       "202713  07/24/1994         29                        HOUSTON,HARRIS,TEXAS   \n",
       "202714  03/11/2012         80          GREENBELT,PRINCE GEORGE'S,MARYLAND   \n",
       "202715  10/19/2014         80          GREENBELT,PRINCE GEORGE'S,MARYLAND   \n",
       "202716  07/24/2016         80          GREENBELT,PRINCE GEORGE'S,MARYLAND   \n",
       "202717  06/27/2004         54        KENNEDY SPACE CENTER,BREVARD,FLORIDA   \n",
       "202718  06/12/2016         41                 EDWARDS AFB,KERN,CALIFORNIA   \n",
       "202719  05/05/2002         80          GREENBELT,PRINCE GEORGE'S,MARYLAND   \n",
       "202720  03/28/2010         80          GREENBELT,PRINCE GEORGE'S,MARYLAND   \n",
       "202721  10/11/2009         80             WASHINGTON,DISTRICT OF COLUMBIA   \n",
       "202722  03/13/2011         03           ALBUQUERQUE,BERNALILLO,NEW MEXICO   \n",
       "202723  09/08/1991         29                        HOUSTON,HARRIS,TEXAS   \n",
       "202724  02/09/2014         80          GREENBELT,PRINCE GEORGE'S,MARYLAND   \n",
       "202725  11/05/2012         32            REDSTONE ARSENAL,MADISON,ALABAMA   \n",
       "202726  07/02/2000         80          GREENBELT,PRINCE GEORGE'S,MARYLAND   \n",
       "202727  10/26/2009         80          GREENBELT,PRINCE GEORGE'S,MARYLAND   \n",
       "202728  04/03/2016         29                        HOUSTON,HARRIS,TEXAS   \n",
       "202729  09/30/2007         74        MOFFETT FIELD,SANTA CLARA,CALIFORNIA   \n",
       "202730  09/19/2016         32            REDSTONE ARSENAL,MADISON,ALABAMA   \n",
       "202731  01/30/2000         80          GREENBELT,PRINCE GEORGE'S,MARYLAND   \n",
       "202732  10/29/2006         74        MOFFETT FIELD,SANTA CLARA,CALIFORNIA   \n",
       "202733  01/11/2004         54        KENNEDY SPACE CENTER,BREVARD,FLORIDA   \n",
       "202734  08/26/2001         80          GREENBELT,PRINCE GEORGE'S,MARYLAND   \n",
       "202735         NaN        NaN                                         NaN   \n",
       "202736         NaN        NaN                                         NaN   \n",
       "\n",
       "         ...    sex step_emp supind suplev tenure time_in_grade   tl  \\\n",
       "0        ...      F        9      8     34      1        205.46  NaN   \n",
       "1        ...      F        6      2     26      1         50.00  NaN   \n",
       "2        ...      M        8      8     34      1        124.04  NaN   \n",
       "3        ...      M        2      2     26      1         19.17  NaN   \n",
       "4        ...      F       10      8     34      3          3.98  NaN   \n",
       "5        ...      M        6      8     34      1        107.69  NaN   \n",
       "6        ...      M        5      8     34      1         80.85  NaN   \n",
       "7        ...      M        6      8     34      1        102.88  NaN   \n",
       "8        ...      M        0      2     32      1        229.85  NaN   \n",
       "9        ...      F        6      2     34      1          6.27  NaN   \n",
       "10       ...      M        7      8     34      1         75.75  NaN   \n",
       "11       ...      F       10      8     34      1        205.78  NaN   \n",
       "12       ...      M        7      2     29      1         31.59  NaN   \n",
       "13       ...      M        8      5     34      1        115.75  NaN   \n",
       "14       ...      F       10      5     25      1        262.98  NaN   \n",
       "15       ...      M        5      8     34      1         52.27  NaN   \n",
       "16       ...      M       10      5     34      1         32.04  NaN   \n",
       "17       ...      M        4      8     34      1         11.85  NaN   \n",
       "18       ...      M        8      8     34      1        164.04  NaN   \n",
       "19       ...      M       10      2     27      1        192.14  NaN   \n",
       "20       ...      M        8      8     34      1         64.24  NaN   \n",
       "21       ...      F       10      8     34      3         12.30  NaN   \n",
       "22       ...      M        7      8     34      1         50.91  NaN   \n",
       "23       ...      M        1      8     34      3          1.24  NaN   \n",
       "24       ...      F        2      8     34      1          7.20  NaN   \n",
       "25       ...      M       10      8     34      1        214.46  NaN   \n",
       "26       ...      M        0      2     26      0         10.43  NaN   \n",
       "27       ...      M       10      8     34      3          0.33  NaN   \n",
       "28       ...      F        2      8     34      1         12.75  NaN   \n",
       "29       ...      M        8      8     34      2         17.33  NaN   \n",
       "...      ...    ...      ...    ...    ...    ...           ...  ...   \n",
       "202707   ...      F        8      8     34      1        109.59  NaN   \n",
       "202708   ...      M        7      2     29      1         28.62  NaN   \n",
       "202709   ...      M        5      8     34      1         54.91  NaN   \n",
       "202710   ...      M        6      8     32      1          1.52  NaN   \n",
       "202711   ...      M        7      2     29      1        131.68  NaN   \n",
       "202712   ...      M        3      8     34      1         14.36  NaN   \n",
       "202713   ...      F       10      8     34      1        265.98  NaN   \n",
       "202714   ...      F        5      8     34      1         54.39  NaN   \n",
       "202715   ...      F        4      8     34      1         23.14  NaN   \n",
       "202716   ...      F        5      2     27      1          1.98  NaN   \n",
       "202717   ...      F        8      8     34      1        146.88  NaN   \n",
       "202718   ...      F        5      8     34      1          3.36  NaN   \n",
       "202719   ...      M       10      8     34      1        172.59  NaN   \n",
       "202720   ...      M        7      8     34      1         77.85  NaN   \n",
       "202721   ...      M        0      2     26      0         83.39  NaN   \n",
       "202722   ...      M        8      8     34      1         66.33  NaN   \n",
       "202723   ...      M       10      8     34      1        300.49  NaN   \n",
       "202724   ...      F        5      5     29      1         31.46  NaN   \n",
       "202725   ...      M        4      8     34      1         46.59  NaN   \n",
       "202726   ...      M        9      8     34      1        194.68  NaN   \n",
       "202727   ...      M        5      8     34      1         82.91  NaN   \n",
       "202728   ...      F        4      8     34      1          5.65  NaN   \n",
       "202729   ...      M        9      8     34      1        107.78  NaN   \n",
       "202730   ...      M        1      8     34      2          0.14  NaN   \n",
       "202731   ...      M       10      8     34      1        199.78  NaN   \n",
       "202732   ...      M        8      8     34      1        118.81  NaN   \n",
       "202733   ...      M       10      8     34      1        152.39  NaN   \n",
       "202734   ...      M        0      8     34      1        180.91  NaN   \n",
       "202735   ...    NaN      NaN    NaN    NaN    NaN           NaN  NaN   \n",
       "202736   ...    NaN      NaN    NaN    NaN    NaN           NaN  NaN   \n",
       "\n",
       "                                      ttl typappt worksch  \n",
       "0                                     NaN      10       F  \n",
       "1                                     NaN      10       F  \n",
       "2                                     NaN      10       F  \n",
       "3                                     NaN      10       F  \n",
       "4                                     NaN      20       F  \n",
       "5                                     NaN      10       F  \n",
       "6                                     NaN      10       F  \n",
       "7                                     NaN      10       F  \n",
       "8                                     NaN      10       F  \n",
       "9                                     NaN      10       F  \n",
       "10                                    NaN      10       F  \n",
       "11                                    NaN      10       F  \n",
       "12                                    NaN      10       F  \n",
       "13                                    NaN      10       F  \n",
       "14                                    NaN      10       F  \n",
       "15                                    NaN      10       F  \n",
       "16                                    NaN      10       F  \n",
       "17                                    NaN      10       F  \n",
       "18                                    NaN      10       F  \n",
       "19                                    NaN      10       F  \n",
       "20                                    NaN      10       F  \n",
       "21                                    NaN      20       F  \n",
       "22                                    NaN      10       F  \n",
       "23                                    NaN      20       F  \n",
       "24                                    NaN      10       F  \n",
       "25                                    NaN      10       F  \n",
       "26                                    NaN      50       F  \n",
       "27                                    NaN      20       F  \n",
       "28                                    NaN      10       F  \n",
       "29                                    NaN      15       F  \n",
       "...                                   ...     ...     ...  \n",
       "202707           AEROSPACE FLIGHT SYSTEMS      10       F  \n",
       "202708      RVISORY AST, SOFTWARE SYSTEMS      10       F  \n",
       "202709                                NaN      10       F  \n",
       "202710                                NaN      10       F  \n",
       "202711                                NaN      10       F  \n",
       "202712      ARCH AST, AEROSPACE MATERIALS      10       F  \n",
       "202713              , TELECOMMUNICATIONS)      10       F  \n",
       "202714                                NaN      10       F  \n",
       "202715                                NaN      10       F  \n",
       "202716                                NaN      10       F  \n",
       "202717                                NaN      10       F  \n",
       "202718                                NaN      10       F  \n",
       "202719                                NaN      10       F  \n",
       "202720        , AEROSPACE FLIGHT SYSTEMS)      10       F  \n",
       "202721                                NaN      50       F  \n",
       "202722                                NaN      10       F  \n",
       "202723        , AEROSPACE FLIGHT SYSTEMS)      10       F  \n",
       "202724                                NaN      10       F  \n",
       "202725     ARCH AST, FIELDS AND PARTICLES      10       F  \n",
       "202726           AEROSPACE FLIGHT SYSTEMS      10       F  \n",
       "202727  ,ATMOSPHERIC CHEMISTRY & DYNAMIC)      10       F  \n",
       "202728                                NaN      10       F  \n",
       "202729                    FLUID MECHANICS      10       F  \n",
       "202730     ARCH AST, FIELDS AND PARTICLES      15       F  \n",
       "202731           AEROSPACE FLIGHT SYSTEMS      10       F  \n",
       "202732                                NaN      10       F  \n",
       "202733      , SAFETY & MISSION ASSURANCE)      10       F  \n",
       "202734                                NaN      10       F  \n",
       "202735                                NaN     NaN     NaN  \n",
       "202736                                NaN     NaN     NaN  \n",
       "\n",
       "[202737 rows x 57 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combining dataframes \n",
    "df = [data_file, data_file2, data_file3, data_file4, data_file5, data_file6, data_file7, data_file8, data_file9, data_file10, data_file11]\n",
    "\n",
    "cdf = pd.concat(df, axis=0, join='outer', join_axes=None, ignore_index=False,\n",
    "          keys=None, levels=None, names=None, verify_integrity=False,\n",
    "          copy=True)\n",
    "cdf.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# dropping columns we are not using for the analysis\n",
    "cdf.drop('Unnamed: 28', axis=1, inplace=True)\n",
    "cdf.drop('agency', axis=1, inplace=True)\n",
    "cdf.drop('coopsch', axis=1, inplace=True)\n",
    "cdf.drop('coopyr', axis=1, inplace=True)\n",
    "cdf.drop('dtystn_ind', axis=1, inplace=True)\n",
    "cdf.drop('dtystnname', axis=1, inplace=True)\n",
    "cdf.drop('edlev', axis=1, inplace=True)\n",
    "cdf.drop('foulev', axis=1, inplace=True)\n",
    "cdf.drop('fousch', axis=1, inplace=True)\n",
    "cdf.drop('fouyr', axis=1, inplace=True)\n",
    "cdf.drop('nasattl', axis=1, inplace=True)\n",
    "cdf.drop('nasa', axis=1, inplace=True)\n",
    "cdf.drop('nasat', axis=1, inplace=True)\n",
    "cdf.drop('probenddte', axis=1, inplace=True)\n",
    "cdf.drop('promontedte', axis=1, inplace=True)\n",
    "cdf.drop('secsch', axis=1, inplace=True)\n",
    "cdf.drop('seclev', axis=1, inplace=True)\n",
    "cdf.drop('typappt', axis=1, inplace=True)\n",
    "cdf.drop('tl', axis=1, inplace=True)\n",
    "cdf.drop('ttl', axis=1, inplace=True)\n",
    "cdf.drop('worksch', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cdf = cdf[cdf.bdyr != 1900]\n",
    "cdf.salary = cdf.salary.astype(np.float64)\n",
    "cdf.time_in_grade = cdf.time_in_grade.astype(np.float64)\n",
    "cdf.suplev = cdf.suplev.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# converting bdyr column to age\n",
    "#now = datetime.datetime.now()\n",
    "now = date(2016,12,31)\n",
    "cdf['bdyr'] = cdf['bdyr'].apply(pd.to_numeric, errors='coerce') \n",
    "cdf['age'] = now.year - cdf['bdyr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     Jr_Level\n",
      "2    Mid_Level\n",
      "3     Jr_Level\n",
      "4    Mid_Level\n",
      "5     Jr_Level\n",
      "Name: salary_range, dtype: category\n",
      "Categories (4, object): [Entry_Level < Jr_Level < Mid_Level < Mgmt_Level]\n"
     ]
    }
   ],
   "source": [
    "cdf['salary_range'] = pd.cut(cdf['salary'],[0,50000,100000,135000,150000],4,labels=['Entry_Level','Jr_Level','Mid_Level', 'Mgmt_Level'])\n",
    "print(cdf['salary_range'].head())\n",
    "cdf.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149993.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdf.salary.max() #Is the salary range cut-off still valid with the new data? Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# convert cdf variable back to \"df\" nomenclature\n",
    "df = pd.DataFrame(cdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#manipulate employee start date 'eoddte' to get 'service' variable\n",
    "#convert 'eoddte' to series\n",
    "df.eod = pd.Series(df['eoddte'])\n",
    "#convert 'eoddte' series to 'eoddte' datetime\n",
    "df['eoddte'] = pd.to_datetime(df.eod) \n",
    "#convert eod to be just the year\n",
    "df['eodyr'] = df['eoddte'].map(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#convert high school graduation year \"hiyr\" to be numeric\n",
    "df['hiyr'] = df['hiyr'].apply(pd.to_numeric, errors='coerce')\n",
    "#after looking at a crosstab, we can see that there are a lot of \"high school graduation year: 0\"\n",
    "#this is a data entry error, let's remove these entries...\n",
    "df = df[df.hiyr != 0]\n",
    "pd.crosstab(index=df[\"hiyr\"],columns=\"hiyr\")\n",
    "#now the 0 entries have been removed\n",
    "\n",
    "#subtract employee hire date from high school graduation date to get exprience\n",
    "df['experience'] = df['eodyr'] - df['hiyr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#get the 'service' variable by subtracting current date from hire date\n",
    "today = date(2016, 12, 31)\n",
    "\n",
    "df['service'] = today - df['eoddte']\n",
    "#generate retirement potential by subtracting retirement eligibility date from todays date  \n",
    "#convert retoptdte to series for conversion to datetime format\n",
    "df.retoptdte = pd.Series(df['retoptdte'])\n",
    "#convert 'retoptdte' series to 'eoddte' datetime\n",
    "df['retoptdte'] = pd.to_datetime(df.retoptdte) \n",
    "#generate 'retpot' variable\n",
    "df['retpot'] = today - df['retoptdte']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_grouped = df.groupby(by=['grade','sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_grouped = df.groupby(by=['grade','sex'])\n",
    "df_imputed = df_grouped.transform(lambda grp: grp.fillna(grp.median()))\n",
    "df_imputed[['grade','sex']] = df[['grade','sex']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df['Hist_yr'] = df['Hist_yr'].astype(np.float64)\n",
    "df_yrgroup = df.groupby(by=['Hist_yr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# creating new dataframe. Keeping original seperate.\n",
    "DF_NoT = df.copy()\n",
    "# perform one-hot encoding of the categorical data \"salary_range\" and \"rno\" (ethnic background).\n",
    "tmp_df = pd.get_dummies(df.salary_range,prefix='salary_range')\n",
    "tmp_df2 = pd.get_dummies(df.rno,prefix='rno')\n",
    "\n",
    "DF_NoT = pd.concat((df,tmp_df),axis=1) # add back into the dataframe\n",
    "DF_NoT = pd.concat((DF_NoT,tmp_df2),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Delete time/dates - can't be used in L-Regression\n",
    "DF_NoT = DF_NoT.drop(['eoddte','retoptdte','salary_range', 'currgrddte', 'frscdte', 'fscdte', 'hisch', 'leqdte',\n",
    "                     'loccde','ncc', 'opmtitle', 'occode', 'orga', 'orgabr', 'orgadir', 'orgadiv',  'orgasec', \n",
    "                     'postenure', 'tenure', 'supind', 'suplev', 'rno', 'rno_000010', 'rno_100100', 'rno_100001', \n",
    "                     'rno_100010', 'rno_100101', 'rno_100000', 'rno_011000', 'rno_001101', 'rno_010001', 'rno_010101',\n",
    "                     'rno_001100', 'rno_010000', 'rno_010100', 'rno_001001', 'rno_001000', 'rno_000101', 'rno_000100',\n",
    "                     'rno_000011', 'rno_101000', 'rno_101101', 'rno_110000', 'rno_110001', 'rno_110101', 'rno_111111',\n",
    "                     'rno_10', 'rno_11', 'rno_100', 'rno_101', 'rno_1000', 'rno_1001', 'rno_1100', 'rno_1101', 'rno_10000',\n",
    "                     'rno_10001', 'rno_10100', 'rno_10101', 'rno_101100', 'rno_000000', 'rno_000110', 'rno_000111', \n",
    "                     'rno_001010', 'rno_001011', 'rno_010111', 'rno_011001', 'rno_011100', 'rno_011101', 'rno_100011', \n",
    "                      'rno_101001', 'rno_1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "today = date(2016, 12, 31) #modify if more datasets are added\n",
    "DF_NoT.service = DF_NoT.service / np.timedelta64(1, 'D')\n",
    "DF_NoT.retpot = DF_NoT.retpot / np.timedelta64(1, 'D')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'sex'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-c97297ccb78d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mDF_NoT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretdiscdte\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDF_NoT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretdiscdte\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'D'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mDF_NoT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'IsMale'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDF_NoT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msex\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'M'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mDF_NoT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIsMale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDF_NoT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIsMale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mDF_NoT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sex'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.4/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2742\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2743\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2744\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2746\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'sex'"
     ]
    }
   ],
   "source": [
    "DF_NoT.lastpromodte = pd.Series(DF_NoT['lastpromodte'])\n",
    "#convert 'eoddte' series to 'eoddte' datetime\n",
    "DF_NoT['lastpromodte'] = pd.to_datetime(DF_NoT.lastpromodte) \n",
    "DF_NoT['lastpromodte'] = today - DF_NoT['lastpromodte']\n",
    "\n",
    "#removing the day to calculate a number\n",
    "DF_NoT.lastpromodte = DF_NoT.lastpromodte / np.timedelta64(1, 'D')\n",
    "\n",
    "DF_NoT.nextwigdte = pd.Series(DF_NoT['nextwigdte'])\n",
    "DF_NoT['nextwigdte'] = pd.to_datetime(DF_NoT.nextwigdte) \n",
    "DF_NoT['nextwigdte'] = today - DF_NoT['nextwigdte']\n",
    "DF_NoT.nextwigdte = DF_NoT.nextwigdte / np.timedelta64(1, 'D')\n",
    "\n",
    "DF_NoT.retdiscdte = pd.Series(DF_NoT['retdiscdte'])\n",
    "DF_NoT['retdiscdte'] = pd.to_datetime(DF_NoT.retdiscdte) \n",
    "DF_NoT['retdiscdte'] = today - DF_NoT['retdiscdte']\n",
    "DF_NoT.retdiscdte = DF_NoT.retdiscdte / np.timedelta64(1, 'D')\n",
    "\n",
    "DF_NoT['IsMale'] = DF_NoT.sex=='M' \n",
    "DF_NoT.IsMale = DF_NoT.IsMale.astype(np.int)\n",
    "del DF_NoT['sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DF_Reg2 = DF_NoT.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del DF_Reg2['salary']\n",
    "del DF_Reg2['salary_range_Entry_Level']\n",
    "del DF_Reg2['salary_range_Mid_Level']\n",
    "del DF_Reg2['salary_range_Mgmt_Level']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Data Preperation 2\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<span style=\"color:red\">5 Points - Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created).</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 126967 entries, 2 to 17523\n",
      "Data columns (total 20 columns):\n",
      "Hist_yr                  126967 non-null float64\n",
      "bdyr                     126967 non-null float64\n",
      "grade                    126967 non-null object\n",
      "hilev                    126967 non-null object\n",
      "hiyr                     126967 non-null int64\n",
      "install                  126967 non-null object\n",
      "lastpromodte             126967 non-null float64\n",
      "nextwigdte               126967 non-null float64\n",
      "retdiscdte               126967 non-null float64\n",
      "secyr                    126967 non-null object\n",
      "step_emp                 126967 non-null object\n",
      "time_in_grade            126967 non-null float64\n",
      "age                      126967 non-null float64\n",
      "eodyr                    126967 non-null int64\n",
      "experience               126967 non-null int64\n",
      "service                  126967 non-null float64\n",
      "retpot                   126967 non-null float64\n",
      "salary_range_Jr_Level    126967 non-null uint8\n",
      "rno_000001               126967 non-null uint8\n",
      "IsMale                   126967 non-null int64\n",
      "dtypes: float64(9), int64(4), object(5), uint8(2)\n",
      "memory usage: 18.6+ MB\n"
     ]
    }
   ],
   "source": [
    "DF_Reg2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Based on the output above, you can see we have about 126,967 entries with 24 columns. \n",
    "New Variables created are:\n",
    "- the age category derived from the \"birth year\" variable\n",
    "- the salary_range category derived by dividing up the salary variable into 4 categories\n",
    "- the salary_range_entry_level is a dummy variable established form the salary range category\n",
    "- the salary_range_jr_level is a dummy variable established form the salary range category\n",
    "- the salary_range_mid_level is a dummy variable established form the salary range category\n",
    "- the salary_range_mgmt_level is a dummy variable established form the salary range category\n",
    "- the eodyr variable which shows the year of employment\n",
    "- the experience variable derived from the high school graduation year subtracted from the last date of the data set (12/31/2016)\n",
    "- the serivce variable derived from the year of employment subtracted from 12/31/2016\n",
    "- the retirement potential derived from the date of earliest reitrement subtracted from 12/31/2016\n",
    "- the rno_000001 variable is derived from the RNO or diversity classification category where 000001 represents the Caucasian Identity Classification\n",
    "- the IsMale variable is a dummy variable established from the gender classification variable.\n",
    "\n",
    "Let's use the variables to predict future records in the NASA human resources data set\n",
    "- which model can we use to predict a \"junior salary range level\" classification, given the variables we have\n",
    "- which model can we use to predict a \"caucasian\" race classification, given the variables we have\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Modeling and Evaluation 1\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<span style=\"color:red\">10 Points - Choose and explain your evaluation metrics that you will use (i.e., accuracy,\n",
    "precision, recall, F-measure, or any metric we have discussed). Why are the measure(s) appropriate for analyzing the results of your modeling? Give a detailed explanation backing up any assertions.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We utilized “ACCURACY” as our evaluation metric of choice because we want to classify a salary range and the diversity (race/national origin) category.  A low false positive score is ideal because we do not want to incorrectly classify the data points.  All things being equal, it would be better if we had more false negatives. For this dataset, logic steers us to be accurate overall since we have four classes of salary range and multiple classes for the diversity classification.  An argument can be made for looking at false negatives on a per class basis. For instance, after reviewing our initial data exploration, we found that the salary range class was unevenly distributed, so we might observe a low count of false positives. This makes sense since a person in a salary range with relatively few measured data points may trigger a low amount of false negatives under some models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN junior salary range accuracy 0.831877574488\n",
      "[[71338 10352]\n",
      " [10994 34283]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "# X = create a matrix with all variable except response variable in it. rno_000001\n",
    "# Y = this should be predictor variable\n",
    "# create variables we are more familiar with\n",
    "DF_NoT_KNN= DF_Reg2.copy()\n",
    "del DF_NoT_KNN['salary_range_Jr_Level']\n",
    "\n",
    "X = DF_NoT_KNN.as_matrix()\n",
    "y = DF_Reg2['salary_range_Jr_Level'].as_matrix()\n",
    "\n",
    "\n",
    "yhat = np.zeros(y.shape) # we will fill this with predictions\n",
    "\n",
    "# create cross validation iterator\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# get a handle to the classifier object, which defines the type\n",
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# now iterate through and get predictions, saved to the correct row in yhat\n",
    "for train, test in cv.split(X,y):\n",
    "    clf.fit(X[train],y[train])\n",
    "    yhat[test] = clf.predict(X[test])\n",
    "\n",
    "KNNs_total_accuracy = mt.accuracy_score(y, yhat)\n",
    "KNNs_conf = mt.confusion_matrix(y, yhat)\n",
    "print ('KNN junior salary range accuracy', KNNs_total_accuracy)\n",
    "print(KNNs_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Using the KNN accuracy rating for 'Junior Salary Range Level', we can compare the KNN model to other models. The accuracy score is 99% so it will be interesting to see if any of the other models can beat it.\n",
    "\n",
    "http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/\n",
    "\n",
    "true positives (TP): These are cases in which we predicted yes (they have the disease), and they do have the disease.\n",
    "true negatives (TN): We predicted no, and they don't have the disease.\n",
    "false positives (FP): We predicted yes, but they don't actually have the disease. (Also known as a \"Type I error.\")\n",
    "false negatives (FN): We predicted no, but they actually do have the disease. (Also known as a \"Type II error.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Adversity Accuracy 0.808997613553\n",
      "[[24886 16981]\n",
      " [ 7270 77830]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "# X = create a matrix with all variable except response variable in it. rno_000001\n",
    "# Y = this should be predictor variable\n",
    "# create variables we are more familiar with\n",
    "DF_NoT_KNN2= DF_Reg2.copy()\n",
    "del DF_NoT_KNN2['rno_000001']\n",
    "\n",
    "X2 = DF_NoT_KNN2.as_matrix()\n",
    "y2 = DF_Reg2['rno_000001'].as_matrix()\n",
    "\n",
    "\n",
    "yhat2 = np.zeros(y2.shape) # we will fill this with predictions\n",
    "\n",
    "# create cross validation iterator\n",
    "cv = StratifiedKFold(n_splits=3)\n",
    "\n",
    "# get a handle to the classifier object, which defines the type\n",
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# now iterate through and get predictions, saved to the correct row in yhat\n",
    "for train, test in cv.split(X2,y2):\n",
    "    clf.fit(X2[train],y2[train])\n",
    "    yhat2[test] = clf.predict(X2[test])\n",
    "\n",
    "KNNr_total_accuracy2 = mt.accuracy_score(y2, yhat2)\n",
    "KNNr_conf2 = mt.confusion_matrix(y2, yhat2)\n",
    "print ('KNN Adversity Accuracy', KNNr_total_accuracy2)\n",
    "print(KNNr_conf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Using the KNN accuracy rating for 'rno_00001' or the adveristy classifier, we can compare the KNN model to other models. The accuracy score is about 55% so let's see if any other models can provide better results. \n",
    "Compared to the Salary Range Accuracy, the Adversity Accuracy score is not that good. However, this makes sense since NASA works hard to maintain a diverse workforce both across departments and across management levels.\n",
    "\n",
    "http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/\n",
    "\n",
    "true positives (TP): These are cases in which we predicted yes (they have the disease), and they do have the disease.\n",
    "true negatives (TN): We predicted no, and they don't have the disease.\n",
    "false positives (FP): We predicted yes, but they don't actually have the disease. (Also known as a \"Type I error.\")\n",
    "false negatives (FN): We predicted no, but they actually do have the disease. (Also known as a \"Type II error.\")\n",
    "\n",
    "EXPLAINING THE CONFUSION MATRIX: \n",
    "we have 77830 as the TRUE positive. This means that for every employee entry that we predict is Caucasian, based on our model, our data also shows that the employee is Caucasian.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Modeling and Evaluation 2\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<span style=\"color:red\">10 Points - Choose the method you will use for dividing your data into training and testing splits (i.e., are you using Stratified 10-fold cross validation? Why?). Explain why your chosen method is appropriate or use more than one method as appropriate. For example, if you are using time series data then you should be using continuous training and testing sets across time </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "After running the previous code, we realized that we might be able to improve our accuracy score by increasing the number of stratified k fold splits from 3 to 10. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Adversity Accuracy with 10 splits 0.864452968094\n",
      "[[29006 12861]\n",
      " [ 4349 80751]]\n",
      "---------------------------------------\n",
      "KNN Adversity Accuracy with 3 splits 0.808997613553\n",
      "[[24886 16981]\n",
      " [ 7270 77830]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "# X = create a matrix with all variable except response variable in it. rno_000001\n",
    "# Y = this should be predictor variable\n",
    "# create variables we are more familiar with\n",
    "DF_NoT_KNN2= DF_Reg2.copy()\n",
    "del DF_NoT_KNN2['rno_000001']\n",
    "\n",
    "X2 = DF_NoT_KNN2.as_matrix()\n",
    "y2 = DF_Reg2['rno_000001'].as_matrix()\n",
    "\n",
    "\n",
    "yhat2 = np.zeros(y2.shape) # we will fill this with predictions\n",
    "\n",
    "# create cross validation iterator\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# get a handle to the classifier object, which defines the type\n",
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# now iterate through and get predictions, saved to the correct row in yhat\n",
    "for train, test in cv.split(X2,y2):\n",
    "    clf.fit(X2[train],y2[train])\n",
    "    yhat2[test] = clf.predict(X2[test])\n",
    "\n",
    "KNNr2_total_accuracy2 = mt.accuracy_score(y2, yhat2)\n",
    "KNNr2_conf2 = mt.confusion_matrix(y2, yhat2)\n",
    "print ('KNN Adversity Accuracy with 10 splits', KNNr2_total_accuracy2)\n",
    "print(KNNr2_conf2)\n",
    "print('---------------------------------------')\n",
    "print ('KNN Adversity Accuracy with 3 splits', KNNr_total_accuracy2)\n",
    "print(KNNr_conf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "After re-running the test with additional splits for the statified k fold cross validation iterator, we can see that the accuracy score increased from 55% to 65%. While normally, we assume that changing to a larger k does not have much effect for a dataset with close to 130,000 records, we can see that there is quite an increase in the accuracy score. We are also optimistic that using a larger k will help mitigate the amount of bias towards overestimating the true expected error because training folds will be more closely related to the total dataset.\n",
    "\n",
    "source: http://stats.stackexchange.com/questions/27730/choice-of-k-in-k-fold-cross-validation\n",
    "\n",
    "\n",
    "http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/\n",
    "\n",
    "true positives (TP): These are cases in which we predicted yes (they have the disease), and they do have the disease.\n",
    "true negatives (TN): We predicted no, and they don't have the disease.\n",
    "false positives (FP): We predicted yes, but they don't actually have the disease. (Also known as a \"Type I error.\")\n",
    "false negatives (FN): We predicted no, but they actually do have the disease. (Also known as a \"Type II error.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Modeling and Evaluation 3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<span style=\"color:red\">20 Points - Create three different classification/regression models for each task (e.g., random forest, KNN, and SVM for task one and the same or different algorithms for task two). Two modeling techniques must be new (but the third could be SVM or logistic regression). Adjust parameters as appropriate to increase generalization performance using your chosen metric. You must investigate different parameters of the algorithms!</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Since we ran the KNN for the previous output, you will find the Random Forest Classifier code below with the SVM code following."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### RANDOM FOREST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Salary_Range_Jr_level 0.932565154725\n",
      "[[74582  7108]\n",
      " [ 1454 43823]]\n"
     ]
    }
   ],
   "source": [
    "###NOTE THIS TAKES A VERY LONG TIME TO RUN\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=50, n_estimators=150, n_jobs=-1, oob_score=True)\n",
    "\n",
    "# now iterate through and get predictions, saved to the correct row in yhat\n",
    "for train, test in cv.split(X,y):\n",
    "    clf.fit(X[train],y[train])\n",
    "    yhat[test] = clf.predict(X[test])\n",
    "    \n",
    "RFs_total_accuracy = mt.accuracy_score(y, yhat)\n",
    "RFs_conf = mt.confusion_matrix(y, yhat)\n",
    "print ('Accuracy for Salary_Range_Jr_level', RFs_total_accuracy)\n",
    "print (RFs_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for rno_0001 0.815542621311\n",
      "[[24344 17523]\n",
      " [ 5897 79203]]\n"
     ]
    }
   ],
   "source": [
    "###NOTE THIS TAKES A VERY LONG TIME TO RUN\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=50, n_estimators=150, n_jobs=-1, oob_score=True)\n",
    "\n",
    "# now iterate through and get predictions, saved to the correct row in yhat\n",
    "for train, test in cv.split(X2,y2):\n",
    "    clf.fit(X2[train],y2[train])\n",
    "    yhat2[test] = clf.predict(X2[test])\n",
    "    \n",
    "RFr_total_accuracy2 = mt.accuracy_score(y2, yhat2)\n",
    "RFr_conf2 = mt.confusion_matrix(y2, yhat2)\n",
    "print ('Accuracy for rno_0001', RFr_total_accuracy2)\n",
    "print (RFr_conf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "It seems like we were more accurate for both tasks using the random forest classifier. Let's try to rerun with different parameters and see if our model improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Salary_Range_Jr_level 0.902770011105\n",
      "[[72408  9282]\n",
      " [ 3063 42214]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=10, n_estimators=50, n_jobs=-1, oob_score=True)\n",
    "\n",
    "# now iterate through and get predictions, saved to the correct row in yhat\n",
    "for train, test in cv.split(X,y):\n",
    "    clf.fit(X[train],y[train])\n",
    "    yhat[test] = clf.predict(X[test])\n",
    "    \n",
    "RFs_total_accuracy = mt.accuracy_score(y, yhat)\n",
    "RFs_conf = mt.confusion_matrix(y, yhat)\n",
    "print ('Accuracy for Salary_Range_Jr_level', RFs_total_accuracy)\n",
    "print (RFs_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for rno_0001 0.734190773981\n",
      "[[13552 28315]\n",
      " [ 5434 79666]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=10, n_estimators=50, n_jobs=-1, oob_score=True)\n",
    "\n",
    "# now iterate through and get predictions, saved to the correct row in yhat\n",
    "for train, test in cv.split(X2,y2):\n",
    "    clf.fit(X2[train],y2[train])\n",
    "    yhat2[test] = clf.predict(X2[test])\n",
    "    \n",
    "RFr_total_accuracy2 = mt.accuracy_score(y2, yhat2)\n",
    "RFr_conf2 = mt.confusion_matrix(y2, yhat2)\n",
    "print ('Accuracy for rno_0001', RFr_total_accuracy2)\n",
    "print (RFr_conf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Salary_Range_Jr_level 0.902770011105\n",
      "[[72408  9282]\n",
      " [ 3063 42214]]\n",
      "----------------\n",
      "Accuracy for rno_0001 0.734190773981\n",
      "[[13552 28315]\n",
      " [ 5434 79666]]\n"
     ]
    }
   ],
   "source": [
    "print ('Accuracy for Salary_Range_Jr_level', RFs_total_accuracy)\n",
    "print (RFs_conf)\n",
    "print ('----------------')\n",
    "print ('Accuracy for rno_0001', RFr_total_accuracy2)\n",
    "print (RFr_conf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "After adjusting the parameters, we did not see any improvement in the accuracy score for the junior level salary range or diversity classifier. Lowering the max_depth and the n_estimators for the random forest classifier actually decreased our accuracy scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### SVM for 'salary_range_jr_level'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.4/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR accuracy: 0.804706697751\n",
      "[[18638  1641]\n",
      " [ 4558  6905]]\n",
      "SVM accuracy: 0.861665931573\n",
      "[[18859  1420]\n",
      " [ 2971  8492]]\n"
     ]
    }
   ],
   "source": [
    "###NOTE THIS TAKES A VERY LONG TIME TO RUN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "lr_clf = LogisticRegression(penalty='l2', C=1.0, class_weight=None)\n",
    "\n",
    "if 'salary_range_Jr_Level' in DF_Reg2:\n",
    "    y = DF_Reg2['salary_range_Jr_Level'].values \n",
    "    del DF_Reg2['salary_range_Jr_Level']\n",
    "    X = DF_Reg2.values\n",
    "\n",
    "num_cv_iterations = 4\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n=num_instances,\n",
    "                         n_iter=4, #num_cv_iterations\n",
    "                         test_size  = 0.25)  \n",
    "\n",
    "for train_indices, test_indices in cv_object: \n",
    "   \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "for iter_num, (train_indices, test_indices) in enumerate(cv_object):\n",
    "    lr_clf.fit(X[train_indices],y[train_indices])  # train object\n",
    "    y_hat = lr_clf.predict(X[test_indices]) # get test set precitions\n",
    "    \n",
    "scl_obj = StandardScaler()\n",
    "scl_obj.fit(X[train_indices]) # find scalings for each column that make this zero mean and unit std\n",
    "# the line of code above only looks at training data to get mean and std and we can use it \n",
    "# to transform new feature data\n",
    "\n",
    "X_train_scaled = scl_obj.transform(X[train_indices]) # apply to training\n",
    "X_test_scaled = scl_obj.transform(X[test_indices]) # apply those means and std to the test set (without snooping at the test set values)\n",
    "\n",
    "# train the model just as before\n",
    "svm_clf = SVC(C=0.5, kernel='linear', degree=3, gamma='auto') # get object\n",
    "svm_clf.fit(X_train_scaled, y[train_indices])  # train object\n",
    "\n",
    "y_hat2 = svm_clf.predict(X_test_scaled) # get test set precitions\n",
    "\n",
    "LRs_acc = mt.accuracy_score(y[test_indices],y_hat)\n",
    "LRs_conf = mt.confusion_matrix(y[test_indices],y_hat)\n",
    "print('LR accuracy:', LRs_acc )\n",
    "print(LRs_conf)\n",
    "\n",
    "SVMs_acc2 = mt.accuracy_score(y[test_indices],y_hat2)\n",
    "SVMs_conf2 = mt.confusion_matrix(y[test_indices],y_hat2)\n",
    "print('SVM accuracy:', SVMs_acc2 )\n",
    "print(SVMs_conf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45844, 19)\n",
      "(45844,)\n",
      "[22928 22916]\n"
     ]
    }
   ],
   "source": [
    "# look at the support vectors\n",
    "print(svm_clf.support_vectors_.shape)\n",
    "print(svm_clf.support_.shape)\n",
    "print(svm_clf.n_support_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.16662692  0.01671184 -1.15118862 -0.17805341  0.01671184 -0.02346974\n",
      "  -0.39804587  0.04287042  0.05996439  0.03234634 -0.58931186 -0.06361336\n",
      "  -0.01671184 -0.11794401 -0.14709568 -0.25502608  0.09439807  0.02888159\n",
      "  -0.01379381]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEuCAYAAACESglMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x138ecad30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(svm_clf.coef_)\n",
    "try:\n",
    "    weights = pd.Series(svm_clf.coef_[0],index=DF_Reg2.columns)\n",
    "    weights.plot(kind='bar')\n",
    "except:    \n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Comparing between the Logistic Regression and the SVM, the SVM provided a better accuracy score for the Junior Level Salary Range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### SVM for Diversity Classifier (RNO_000001 = Caucasian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "DF_Reg3 = DF_Reg2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.4/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR accuracy: 0.671318757482\n",
      "[[    0 10432]\n",
      " [    1 21309]]\n",
      "SVM accuracy: 0.671350261483\n",
      "[[    0 10432]\n",
      " [    0 21310]]\n"
     ]
    }
   ],
   "source": [
    "###NOTE THIS TAKES A VERY LONG TIME TO RUN \n",
    "###runtime approx 30 mins\n",
    "\n",
    "if 'rno_000001' in DF_Reg3:\n",
    "    y2 = DF_Reg3['rno_000001'].values \n",
    "    del DF_Reg3['rno_000001']\n",
    "    X2 = DF_Reg3.values\n",
    "\n",
    "num_cv_iterations = 4\n",
    "num_instances = len(y2)\n",
    "cv_object = ShuffleSplit(n=num_instances,\n",
    "                         n_iter=4, #num_cv_iterations\n",
    "                         test_size  = 0.25)  \n",
    "\n",
    "for train_indices, test_indices in cv_object: \n",
    "   \n",
    "    X_train2 = X2[train_indices]\n",
    "    y_train2 = y2[train_indices]\n",
    "    \n",
    "    X_test2 = X2[test_indices]\n",
    "    y_test2 = y2[test_indices]\n",
    "    \n",
    "for iter_num, (train_indices, test_indices) in enumerate(cv_object):\n",
    "    lr_clf.fit(X2[train_indices],y2[train_indices])  # train object\n",
    "    y_hat3 = lr_clf.predict(X2[test_indices]) # get test set precitions\n",
    "    \n",
    "scl_obj = StandardScaler()\n",
    "scl_obj.fit(X2[train_indices]) # find scalings for each column that make this zero mean and unit std\n",
    "# the line of code above only looks at training data to get mean and std and we can use it \n",
    "# to transform new feature data\n",
    "\n",
    "X2_train_scaled = scl_obj.transform(X2[train_indices]) # apply to training\n",
    "X2_test_scaled = scl_obj.transform(X2[test_indices]) # apply those means and std to the test set (without snooping at the test set values)\n",
    "\n",
    "# train the model just as before\n",
    "svm_clf = SVC(C=0.5, kernel='linear', degree=3, gamma='auto') # get object\n",
    "svm_clf.fit(X2_train_scaled, y2[train_indices])  # train object\n",
    "\n",
    "y_hat4 = svm_clf.predict(X2_test_scaled) # get test set precitions\n",
    "\n",
    "LRr_acc = mt.accuracy_score(y2[test_indices],y_hat3)\n",
    "LRr_conf = mt.confusion_matrix(y2[test_indices],y_hat3)\n",
    "print('LR accuracy:', LRr_acc )\n",
    "print(LRr_conf)\n",
    "\n",
    "SVMr_acc2 = mt.accuracy_score(y2[test_indices],y_hat4)\n",
    "SVMr_conf2 = mt.confusion_matrix(y2[test_indices],y_hat4)\n",
    "print('SVM accuracy:', SVMr_acc2 )\n",
    "print(SVMr_conf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64203, 18)\n",
      "(64203,)\n",
      "[31435 32768]\n"
     ]
    }
   ],
   "source": [
    "# look at the support vectors\n",
    "print(svm_clf.support_vectors_.shape)\n",
    "print(svm_clf.support_.shape)\n",
    "print(svm_clf.n_support_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -5.95087459e-07  -3.56783098e-04   2.02419075e-05  -5.62082577e-05\n",
      "   -3.56783098e-04  -1.69154995e-05  -4.58299324e-05   5.82735135e-05\n",
      "   -2.96026037e-05   7.40360090e-06   1.40879825e-05  -2.90324788e-05\n",
      "    3.56783077e-04  -1.24191687e-03  -9.70027213e-04  -2.31265306e-03\n",
      "   -6.91961974e-05   5.10646933e-05]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x13ea1e2b0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEuCAYAAACUBoXVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13ea1eeb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(svm_clf.coef_)\n",
    "weights = pd.Series(svm_clf.coef_[0],index=DF_Reg3.columns)\n",
    "weights.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Looking at the SVM for rno_000001, the confusion matrix leads us to believe that this measure is not very accurate. However, investigating the weights, we can see that the 'Service', 'EODyr' and 'Experience' variables are very important for the SVM Diversity Classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Modeling and Evaluation 4\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<span style=\"color:red\">10 Points - Analyze the results using your chosen method of evaluation. Use visualizations of the results to bolster the analysis. Explain any visuals and analyze why they are interesting to someone that might use this model. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Results for salary range jr level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Junior Salary Range Accuracy with 10 splits 0.831877574488\n",
      "[[71338 10352]\n",
      " [10994 34283]]\n",
      "--------------------------------------\n",
      "Random Forest Salary_Range_Jr_level Accuracy 0.902770011105\n",
      "[[72408  9282]\n",
      " [ 3063 42214]]\n",
      "--------------------------------------\n",
      "SVM Junior Salary Range accuracy: 0.861665931573\n",
      "[[18859  1420]\n",
      " [ 2971  8492]]\n"
     ]
    }
   ],
   "source": [
    "print ('KNN Junior Salary Range Accuracy with 10 splits', KNNs_total_accuracy)\n",
    "print(KNNs_conf)\n",
    "print('--------------------------------------')\n",
    "print ('Random Forest Salary_Range_Jr_level Accuracy', RFs_total_accuracy)\n",
    "print (RFs_conf)\n",
    "print('--------------------------------------')\n",
    "print('SVM Junior Salary Range accuracy:', SVMs_acc2)\n",
    "print(SVMs_conf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Accuracy: 0.902770011105\n",
      "Number of infrequent classes: 0 with average recall of: nan\n",
      "Number of frequent classes: 2 with average precision of: 0.889583932556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.4/site-packages/numpy/core/fromnumeric.py:2889: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "//anaconda/lib/python3.4/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics as mt\n",
    "\n",
    "freq_infreq_threshold = 40\n",
    "\n",
    "# get various measures of performance\n",
    "total_accuracy = mt.accuracy_score(y, yhat)\n",
    "\n",
    "prec_for_freq_classes = []\n",
    "recall_for_infreq_classes = []\n",
    "rec_tot = []\n",
    "prec_tot = []\n",
    "\n",
    "for cls in np.unique(y):\n",
    "    idx = (y==cls) # get classes\n",
    "    ytmp_actual = np.zeros(y.shape) # make binary class problem\n",
    "    ytmp_actual[idx] = 1 # set the instances for this specific class\n",
    "    \n",
    "    ytmp_predicted = np.zeros(y.shape) # binary prediction array\n",
    "    ytmp_predicted[yhat==cls] = 1\n",
    "    \n",
    "    num_in_class = sum(idx)\n",
    "    \n",
    "    rec = mt.recall_score(ytmp_actual, ytmp_predicted)\n",
    "    prec = mt.precision_score(ytmp_actual, ytmp_predicted)\n",
    "    rec_tot.append(rec)\n",
    "    prec_tot.append(prec)\n",
    "    \n",
    "    if num_in_class < freq_infreq_threshold:\n",
    "        recall_for_infreq_classes.append(rec)\n",
    "    elif num_in_class >= freq_infreq_threshold:\n",
    "        prec_for_freq_classes.append(prec)\n",
    "        \n",
    "print ('Total Accuracy:',total_accuracy)\n",
    "print ('Number of infrequent classes:',len(recall_for_infreq_classes), \n",
    "       'with average recall of:', np.mean(recall_for_infreq_classes))\n",
    "print ('Number of frequent classes:',len(prec_for_freq_classes), \n",
    "       'with average precision of:',np.mean(prec_for_freq_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD7CAYAAAB37B+tAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSSrOIJek4gxySSrOIJek4gxySSru/wESmCuuP34EpwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ec4d518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# But we can really summarize this data much better than this. \n",
    "# How about looking at more statistics of the precision and recall for each class?\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_palette(\"dark\")\n",
    "\n",
    "plt.boxplot([rec_tot, prec_tot, recall_for_infreq_classes,prec_for_freq_classes],labels=['true positive','false positive','true negative','false negative'])\n",
    "plt.ylim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Based on the ACCURACY score, we can see that the most accurate measure for the Junior Salary Range Classifier was the Random Forest and the SVM. Looking at the confusion matrix boxplot above, Random Forest and SVM have are the most accurate but have the worst confusion matrix results. Therefore, we advocate the use of KNN. This will still give an accuracy of 99% with a better confusion matrix result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Results for the rno_00001 classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Adversity Accuracy with 10 splits 0.864452968094\n",
      "[[29006 12861]\n",
      " [ 4349 80751]]\n",
      "--------------------------------------\n",
      "Random Forest Diversity Accuracy 0.734190773981\n",
      "[[13552 28315]\n",
      " [ 5434 79666]]\n",
      "--------------------------------------\n",
      "SVM Diversity accuracy: 0.671350261483\n",
      "[[    0 10432]\n",
      " [    0 21310]]\n"
     ]
    }
   ],
   "source": [
    "print ('KNN Adversity Accuracy with 10 splits', KNNr2_total_accuracy2)\n",
    "print(KNNr2_conf2)\n",
    "print('--------------------------------------')\n",
    "print ('Random Forest Diversity Accuracy', RFr_total_accuracy2)\n",
    "print (RFr_conf2)\n",
    "print('--------------------------------------')\n",
    "print('SVM Diversity accuracy:', SVMr_acc2 )\n",
    "print(SVMr_conf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Accuracy: 0.734190773981\n",
      "Number of infrequent faces: 0 with average recall of: nan\n",
      "Number of frequent faces: 2 with average precision of: 0.72578352509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.4/site-packages/numpy/core/fromnumeric.py:2889: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "//anaconda/lib/python3.4/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics as mt\n",
    "\n",
    "freq_infreq_threshold = 40\n",
    "\n",
    "# get various measures of performance\n",
    "total_accuracy2 = mt.accuracy_score(y2, yhat2)\n",
    "\n",
    "prec_for_freq_classes2 = []\n",
    "recall_for_infreq_classes2 = []\n",
    "rec_tot2 = []\n",
    "prec_tot2 = []\n",
    "\n",
    "for cls in np.unique(y2):\n",
    "    idx = (y2==cls) # get classes\n",
    "    ytmp_actual2 = np.zeros(y2.shape) # make binary class problem\n",
    "    ytmp_actual2[idx] = 1 # set the instances for this specific class\n",
    "    \n",
    "    ytmp_predicted2 = np.zeros(y2.shape) # binary prediction array\n",
    "    ytmp_predicted2[yhat2==cls] = 1\n",
    "    \n",
    "    num_in_class2 = sum(idx)\n",
    "    \n",
    "    rec2 = mt.recall_score(ytmp_actual2, ytmp_predicted2)\n",
    "    prec2 = mt.precision_score(ytmp_actual2, ytmp_predicted2)\n",
    "    rec_tot2.append(rec2)\n",
    "    prec_tot2.append(prec2)\n",
    "    \n",
    "    if num_in_class2 < freq_infreq_threshold:\n",
    "        recall_for_infreq_classes2.append(rec2)\n",
    "    elif num_in_class2 >= freq_infreq_threshold:\n",
    "        prec_for_freq_classes2.append(prec2)\n",
    "        \n",
    "print ('Total Accuracy:',total_accuracy2)\n",
    "print ('Number of infrequent faces:',len(recall_for_infreq_classes2), \n",
    "       'with average recall of:', np.mean(recall_for_infreq_classes2))\n",
    "print ('Number of frequent faces:',len(prec_for_freq_classes2), \n",
    "       'with average precision of:',np.mean(prec_for_freq_classes2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD7CAYAAAB37B+tAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12338c5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# But we can really summarize this data much better than this. \n",
    "# How about looking at more statistics of the precision and recall for each class?\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_palette(\"dark\")\n",
    "\n",
    "plt.boxplot([rec_tot2, prec_tot2, recall_for_infreq_classes2, prec_for_freq_classes2],labels=['true positive','false positive','true negative','false negative'])\n",
    "plt.ylim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Based on the ACCURACY score, we can see that the most accurate measure for the Diversity Classifier was the Random Forest. Random forests showed an accuracy score of 78%. This measure had a solid confusion matrix so we advocate that this test be the best choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Modeling and Evaluation 5\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<span style=\"color:red\">10 Points - Discuss the advantages of each model for each classification task, if any. If there are not advantages, explain why. Is any model better than another? Is the difference significant with 95% confidence? Use proper statistical comparison methods. You must use statistical comparison techniques—be sure they are appropriate for your chosen method of validation as discussed in unit 7 of the course.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Model evaluation for Junior Salary Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'yhat_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-36553aa5fa4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mfpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myhat_score\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mroc_auc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'yhat_score' is not defined"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.set_palette(\"dark\")\n",
    "# code manipulated from http://scikit-learn.org/stable/auto_examples/plot_roc.html\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Compute ROC curve for a subset of interesting classes\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in np.unique(y):\n",
    "    fpr[i], tpr[i], _ = mt.roc_curve(y, yhat_score[:, i], pos_label=i)\n",
    "    roc_auc[i] = mt.auc(fpr[i], tpr[i])\n",
    "\n",
    "for i in np.random.permutation(60)[0:6]:\n",
    "    plt.plot(fpr[i], tpr[i], label='class {0} with {1} instances (area = {2:0.2f})'\n",
    "                                   ''.format(i, sum(y==i), roc_auc[i]))\n",
    "\n",
    "plt.legend(loc=\"lower right\")  \n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Model Evaluation for RNO_00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_palette(\"dark\")\n",
    "# code manipulated from http://scikit-learn.org/stable/auto_examples/plot_roc.html\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Compute ROC curve for a subset of interesting classes\n",
    "fpr2 = dict()\n",
    "tpr2 = dict()\n",
    "roc_auc2 = dict()\n",
    "for i in np.unique(y2):\n",
    "    fpr2[i], tpr[i], _ = mt.roc_curve(y2, yhat2[:, i], pos_label=i)\n",
    "    roc_auc2[i] = mt.auc(fpr2[i], tpr2[i])\n",
    "\n",
    "for i in np.random.permutation(60)[0:6]:\n",
    "    plt.plot(fpr2[i], tpr2[i], label='class {0} with {1} instances (area = {2:0.2f})'\n",
    "                                   ''.format(i, sum(y2==i), roc_auc2[i]))\n",
    "\n",
    "plt.legend(loc=\"lower right\")  \n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Looking at the ROC curve for Junior level salary range we can see the area under the curve has minimal false negatives and false positives for the KNN model. \n",
    "\n",
    "Looking at the ROC curve for the diversity classification we can see the area under the curve has minimal false negatives and false positives for the random forest model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Modeling and Evaluation 6\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<span style=\"color:red\">\n",
    "10 Points - Which attributes from your analysis are most important? Use proper methods discussed in class to evaluate the importance of different attributes. Discuss the results and hypothesize about why certain attributes are more important than others for a given classification task.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Based on the SVM weights output, we know that for the Junior Level Salary Range, the most important variables for analysis were Grade, Service, Last Promoted Date, Step_Emp, and Retdiscdte are the biggest predictors of the Junior Salary Range Level classification. It is interesting to note that in the logistic regression model, 'grade' was not a relevant variable. However, in the SVM model we can see that 'grade' has the largest weight. \n",
    "\n",
    "We suspect that this is because Logistic Regression aims to fit the data points along a continuous function so the 'grade' variable passes into the model with minimal significance. However, for Support Vector Machines, it is easy to separate the data into classes since we can assume most junior salary range level employees are probably also defined by their 'grade' level. We initially defined the categories as follows.\n",
    "\n",
    "'Entry_Level' : $0-50,000\n",
    "'Jr_Level' : $50,000-100,000\n",
    "'Mid_Level' : $100,000-135,000\n",
    "'Mgmt_Level' : $135,000-150,000\n",
    "\n",
    "We know from NASA documentation that pay level is defined by a combination of 'grade', 'step', and 'service'. Knowing this, it makes sense that the biggest predictors of Junior Salary Range are 'grade', 'step' and 'service'. \n",
    "\n",
    "Looking at the SVM weights output for the diversity classifier, most of the variables had minimal effect on the diversity classification. However, 'Service', 'EODyr' and 'Experience' carried the largest amount of weight with Service weighting in at -0.002. We noticed that these variables are all time based. We suspect this may have something to do with their negative correlation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Deployment\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<span style=\"color:red\">5 Points - How useful is your model for interested parties (i.e., the companies or organizations that might want to use it for prediction)? How would you measure the model's value if it was used by these parties? How would your deploy your model for interested parties? What other data should be collected? How often would the model need to be updated, etc.? </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "All Federal Agencies are required to use and store the data elements defined by Office of Personnel Management (OPM). The data elements are defined in the following OPM website: https://www.opm.gov/policy-data-oversight/pay-leave/salaries-wages/salary-tables/datadictionary.aspx\n",
    "\n",
    "We strongly recommend all Human Resources and Workforce Planning offices of the United States Government, especially the Office of Personnel Management (OPM) will benefit from the use of the models and analysis contained in the document. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Exceptional Work\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Classification Using Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble  import GradientBoostingClassifier\n",
    "from sklearn import cross_validation, metrics\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train = DF_NoT.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "target = 'rno_000001' #Binary for being White or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train[target].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Define a function for modeling and cross-validation\n",
    "This function will do the following:\n",
    "1. fit the model\n",
    "2. determine training accuracy\n",
    "3. determine training AUC\n",
    "4. determine testing AUC\n",
    "5. perform CV is performCV is True\n",
    "6. plot Feature Importance if printFeatureImportance is True\n",
    "\n",
    "Source code from https://github.com/aarshayj/Analytics_Vidhya/blob/master/Articles/Parameter_Tuning_GBM_with_Example/GBM%20model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def modelfit(alg, dtrain, predictors, performCV=True, printFeatureImportance=True, cv_folds=5):\n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain['rno_000001'])\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "    \n",
    "    #Perform cross-validation:\n",
    "    if performCV:\n",
    "        cv_score = cross_validation.cross_val_score(alg, dtrain[predictors], dtrain['rno_000001'], cv=cv_folds, scoring='roc_auc')\n",
    "    \n",
    "    #Print model report:\n",
    "    print (\"\\nModel Report\")\n",
    "    print (\"Accuracy : %.4g\" % metrics.accuracy_score(dtrain['rno_000001'].values, dtrain_predictions))\n",
    "    print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain['rno_000001'], dtrain_predprob))\n",
    "    \n",
    "    if performCV:\n",
    "        print (\"CV Score : Mean - %.7g | Std - %.7g | Min - %.7g | Max - %.7g\" % (np.mean(cv_score),np.std(cv_score),np.min(cv_score),np.max(cv_score)))\n",
    "                \n",
    "    #Print Feature Importance:\n",
    "    if printFeatureImportance:\n",
    "        feat_imp = pd.Series(alg.feature_importances_, predictors).sort_values(ascending=False)\n",
    "        feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "        plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Model Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Choose all predictors except the target variable, in this case 'rno_000001'\n",
    "predictors = [x for x in train.columns if x not in [target]]\n",
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gbm0 = GradientBoostingClassifier(random_state=10)\n",
    "modelfit(gbm0, train, predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Describe what you see above ^"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### GBM Models:\n",
    "There 2 types of parameters here:\n",
    "    \n",
    "Tree-specific parameters\n",
    "   \n",
    "2. min_samples_split\n",
    "3. min_samples_leaf\n",
    "4. max_depth\n",
    "5. min_leaf_nodes\n",
    "6. max_features\n",
    "7. loss function\n",
    "   \n",
    "Boosting specific paramters\n",
    "   \n",
    "1. n_estimators\n",
    "2. learning_rate\n",
    "3. subsample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Tune the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Choose all predictors except target & IDcols\n",
    "predictors = [x for x in train.columns if x not in [target]]\n",
    "param_test1 = {'n_estimators':[600, 700, 800, 900, 1000]}\n",
    "gsearch1 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=1, min_samples_split=500,min_samples_leaf=50,max_depth=8, max_features='sqrt', subsample=0.8,random_state=10), \n",
    "param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.fit(train[predictors],train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "So we can see from above that we got 800 as the optimal estimators for the 1.2 learning rate. We started testing at a learning rate of 0.1 and the estimators were well above 1000. We used the following for learning rates and tested for optimal estimators:\n",
    "[0.1, 0.25, 0.5, 1.0, 1.2, 1.5, 2.0, 5.0]. After learning rate 1.5, the mean significantly drops to the mid 0.50's. We will proceed with 800 estimators and 1.2 learning rate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "modelfit(gsearch1.best_estimator_, train, test, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Grid seach on subsample and max_features\n",
    "param_test2 = {'max_depth':[2, 4, 6, 8, 10], 'min_samples_split':[100, 200, 300]}\n",
    "gsearch2 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=800,\n",
    "                                                max_features='sqrt', subsample=0.8, random_state=10), \n",
    "                       param_grid = param_test2, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch2.fit(train[predictors],train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "10 Points - You have free reign to provide additional analyses. One idea: grid search parameters in a parallelized fashion and visualize the performances across attributes. Which parameters are most significant for making a good model for each classification algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
